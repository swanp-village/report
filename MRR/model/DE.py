from dataclasses import dataclass
import joblib
import math
import numpy as np
import numpy.typing as npt
from scipy.optimize import differential_evolution
from cmaes import CMA
from config.random import get_differential_evolution_rng
from MRR.analyzer import analyze
from MRR.evaluator import evaluate_band
from MRR.graph import Graph
from MRR.logger import Logger
from MRR.simulator import (
    calculate_practical_FSR,
    calculate_ring_length,
    calculate_x,
    optimize_N,
)
from MRR.transfer_function import simulate_transfer_function
from scipy.stats.qmc import LatinHypercube
from concurrent.futures import ProcessPoolExecutor
import numpy as np
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from cma import CMAEvolutionStrategy
from typing import Tuple
import numpy.typing as npt
import os
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
from sklearn.gaussian_process.kernels import WhiteKernel
from sklearn.neural_network import MLPRegressor
from sklearn.base import clone
from typing import Tuple,List
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from typing import List, Tuple
from scipy.stats import norm
# ----------------------------------------------------

def optimize_L(
    n_g: float,
    n_eff: float,
    FSR: float,
    center_wavelength: float,
    min_ring_length: float,
    number_of_rings: int,
    rng: np.random.Generator,
) -> tuple[npt.NDArray[np.int_], npt.NDArray[np.float_], np.float_]:
    for i in range(100):
        N = optimize_N(
            center_wavelength=center_wavelength,
            min_ring_length=min_ring_length,
            n_eff=n_eff,
            n_g=n_g,
            number_of_rings=number_of_rings,
            FSR=FSR,
            rng=rng,
        )
        L = calculate_ring_length(center_wavelength=center_wavelength, n_eff=n_eff, N=N)
         
        
        practical_FSR = calculate_practical_FSR(center_wavelength=center_wavelength, n_eff=n_eff, n_g=n_g, N=N)
        if practical_FSR > FSR * 0.99 and practical_FSR < FSR * 1.01 and np.all(L < 0.1):
            break
    if i == 99:
        raise Exception("FSR is too strict")

    return N, L, practical_FSR




@dataclass
class OptimizeKParams:
    L: npt.NDArray[np.float_]
    n_g: float
    n_eff: float
    eta: float
    alpha: float
    center_wavelength: float
    length_of_3db_band: float
    FSR: np.float_
    max_crosstalk: float
    H_p: float
    H_s: float
    H_i: float
    r_max: float
    weight: list[float]


def cma_run(initial, bounds_array, popsize, sigma, generations, params,objective_func):
    # bounds_array: shape (N, 2)
    lower_bounds = bounds_array[:, 0]
    upper_bounds = bounds_array[:, 1]

    opts = {
        'bounds': [lower_bounds, upper_bounds],
        'popsize': popsize,
        'verb_log': 0,
        'verbose': -9,
        'tolfun': 0,        # ç›®çš„é–¢æ•°å€¤ã®æ”¹å–„ã«ã‚ˆã‚‹åœæ­¢ã‚’ç„¡åŠ¹åŒ–
        'tolx': 0,          # æ¢ç´¢ç©ºé–“ã®å¤‰åŒ–ã«ã‚ˆã‚‹åœæ­¢ã‚’ç„¡åŠ¹åŒ–
        'tolfunhist': 0,    # éå»ã®å±¥æ­´ã«ã‚ˆã‚‹åœæ­¢ã‚’ç„¡åŠ¹åŒ–
        'tolflatfitness': 0, # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãŒå¹³å¦ã«ãªã£ãŸã“ã¨ã«ã‚ˆã‚‹åœæ­¢ã‚’ç„¡åŠ¹åŒ–
        'maxiter': generations,  
    }

    es = CMAEvolutionStrategy(initial, sigma, opts)

    best_solution = None
    best_fitness = float("inf")

    for generation in range(generations):
        candidates = es.ask()
        fitnesses = [objective_func(x) for x in candidates]
        es.tell(candidates, fitnesses)
        min_fit = min(fitnesses)
        if min_fit < best_fitness:
            print("best_fitness",best_fitness)
            print("min_fitness",min_fit)
            best_fitness = min_fit
            print("new_best",best_fitness)
            best_solution = candidates[fitnesses.index(min_fit)]

        # ãƒ­ã‚°å‡ºåŠ›ï¼ˆä»»æ„ï¼‰
        #if generation % 50 == 0 or generation == generations - 1:
            #print(f"Gen {generation}: sigma = {es.sigma:.4f}, best_fitness = {best_fitness:.6f}")


    return best_solution, best_fitness  

# --- å¿…é ˆ: CMA-ESã‚’åˆæœŸãƒ‡ãƒ¼ã‚¿åé›†ç”¨ã¨ã—ã¦å®Ÿè¡Œã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def check_overfitting(model, X_train, Y_train, X_test, Y_test):
    """
    è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ R^2 ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€éå­¦ç¿’ã‚’åˆ¤æ–­ã™ã‚‹ã€‚
    
    Args:
        model: è¨“ç·´æ¸ˆã¿ã® MLPRegressor ãƒ¢ãƒ‡ãƒ«
    """
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬
    Y_train_pred = model.predict(X_train)
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬
    Y_test_pred = model.predict(X_test)

    # R^2 ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
    r2_train = r2_score(Y_train, Y_train_pred)
    r2_test = r2_score(Y_test, Y_test_pred)
    
    print("--- R^2 ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹éå­¦ç¿’è¨ºæ–­ ---")
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ R^2: {r2_train:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ R^2: {r2_test:.4f}")
    
    if r2_train > 0.99 and r2_test < 0.90:
        print("\nğŸš¨ è¨ºæ–­çµæœ: é‡å¤§ãªéå­¦ç¿’ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚")
        print("ãƒ¢ãƒ‡ãƒ«ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºã«éå‰°ã«é©åˆã—ã¦ã„ã¾ã™ã€‚")
        print("â–¶ï¸ è§£æ±ºç­–: 'alpha' (æ­£å‰‡åŒ–) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã—ã¦å†è¨“ç·´ã—ã¦ãã ã•ã„ã€‚")
    elif r2_train < 0.90:
        print("\nâš ï¸ è¨ºæ–­çµæœ: ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆå­¦ç¿’ä¸è¶³ï¼‰ã§ã™ã€‚")
    else:
        print("\nâœ… è¨ºæ–­çµæœ: æ±åŒ–æ€§èƒ½ã¯è‰¯å¥½ã§ã™ã€‚æœ€é©åŒ–ã®å•é¡Œã¯æ¢ç´¢æˆ¦ç•¥ã«ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
    return r2_train, r2_test
    
def normalize_K(K_physical: np.ndarray, eta_max: float) -> np.ndarray:
    #ç‰©ç†ã‚¹ã‚±ãƒ¼ãƒ« [1e-12, eta] ã‹ã‚‰ [0, 1] ã«æ­£è¦åŒ–ã™ã‚‹
    K_min = 1e-12
    K_range = eta_max - K_min
    K_normalized = (K_physical - K_min) / K_range
    return np.clip(K_normalized, 0.0, 1.0)

def denormalize_K(K_normalized: np.ndarray, eta_max: float) -> np.ndarray:
    K_min = 1e-12
    K_range = eta_max - K_min
    K_physical = K_normalized * K_range + K_min
    
    # ã€ä»£æ›¿ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°å‡¦ç†ã€‘
    # ç‰©ç†çš„ãªä¸Šé™ eta_max ã‚’è¶…ãˆãªã„ã‚ˆã†ã«åˆ¶é™
    K_physical = np.minimum(K_physical, eta_max) 
    # ä¸‹é™ K_min (1e-12) ã‚ˆã‚Šå°ã•ããªã‚‰ãªã„ã‚ˆã†ã«åˆ¶é™
    K_physical = np.maximum(K_physical, K_min)
    
    return K_physical

def get_beta_schedule(iteration: int, max_iterations: int) -> float:

    # åˆæœŸå€¤ (æ¢ç´¢å„ªå…ˆ): 50.0 
    beta_start = 2
    
    # æœ€çµ‚å€¤ (æ´»ç”¨å„ªå…ˆ): 10.0
    beta_end = 0.5
    
    # å…¨ä½“ã®ç´„80%ã¾ã§å¾ã€…ã«æ¸›å°‘ã•ã›ã‚‹
    decay_ratio = 0.8
    decay_iterations = int(max_iterations * decay_ratio)

    if iteration >= decay_iterations:
        # å¾ŒåŠ20%ã¯æœ€çµ‚å€¤ã«å›ºå®š
        beta = beta_end
    else:
        # ç·šå½¢ã«æ¸›å°‘ã•ã›ã‚‹
        beta = beta_start - (beta_start - beta_end) * (iteration / decay_iterations)

    return beta
 
# --- ã€ANNã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬é–¢æ•°ã€‘ ---
def predict_ensemble(K_2d: np.ndarray,ensemble_models: List[MLPRegressor])-> float:
    predictions = np.array([model.predict(K_2d)[0] for model in ensemble_models])
    
    # äºˆæ¸¬ã®å¹³å‡ã‚’ mu ã«ã€æ¨™æº–åå·®ã‚’ sigma ã«è¨­å®š
    mu = np.mean(predictions)
    sigma = np.std(predictions)
    
    return mu, sigma


def visualize_ann_landscape(ensemble_models: List, params: 'OptimizeKParams', N_rings: int):

    
    # --- 1. è¨­å®šã¨åˆæœŸåŒ– ---
    N_dim = N_rings + 1
    index1, index2 = 0, 1  # å‹•ã‹ã™çµåˆç‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (K[0] ã¨ K[1] ã‚’å‹•ã‹ã™)
    
    k_min, k_max = 0.0, 1.0  # æ­£è¦åŒ–ã•ã‚ŒãŸ [0, 1] ç©ºé–“
    resolution = 50 
    
    # æ®‹ã‚Šã®å¤‰æ•°ã®å›ºå®šå€¤ (å…¨ã¦æ­£è¦åŒ–ã•ã‚ŒãŸ 0.5 ã«å›ºå®š)
    fixed_K_value_norm = 0.5 
    fixed_K_array_norm = np.full(N_dim, fixed_K_value_norm)
    
    # --- 2. ã‚°ãƒªãƒƒãƒ‰ã®ç”Ÿæˆ ---
    k1_range = np.linspace(k_min, k_max, resolution)
    k2_range = np.linspace(k_min, k_max, resolution)
    
    K1_norm, K2_norm = np.meshgrid(k1_range, k2_range)
    Z_mu = np.zeros(K1_norm.shape)  # äºˆæ¸¬å¹³å‡ (Î¼) ã‚’æ ¼ç´ã™ã‚‹é…åˆ—
    
    # --- 3. ã‚°ãƒªãƒƒãƒ‰ã®è©•ä¾¡ï¼ˆANNäºˆæ¸¬ï¼‰ ---
    print(f"è©•ä¾¡é–‹å§‹: {resolution * resolution} å›ã®ANNäºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")
    
    for i in range(resolution):
        for j in range(resolution):
            # æ¢ç´¢ç‚¹ã®ä½œæˆ (K[0], K[1] ã ã‘ã‚’å‹•ã‹ã—ã€æ®‹ã‚Šã¯å›ºå®š)
            K_candidate_norm = fixed_K_array_norm.copy()
            K_candidate_norm[index1] = K1_norm[i, j]
            K_candidate_norm[index2] = K2_norm[i, j]
            
            # ANNã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
            # predict_ensemble ã¯ (mu, sigma) ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™
            mu, sigma = predict_ensemble(K_candidate_norm.reshape(1, -1), ensemble_models)
            
            # äºˆæ¸¬å¹³å‡ (Î¼) ã‚’æ ¼ç´ã€‚ã“ã‚ŒãŒæ»‘ã‚‰ã‹ãªæ¢ç´¢åœ°å½¢ã¨ãªã‚‹ã€‚
            Z_mu[i, j] = mu
            
    print("ANNäºˆæ¸¬å®Œäº†ã€‚")
    
    # --- 4. 3Dæç”» ---
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    
    # ã‚µãƒ¼ãƒ•ã‚§ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆ (cmap='viridis'ã§æ»‘ã‚‰ã‹ã•ã‚’å¼·èª¿)
    surf = ax.plot_surface(K1_norm, K2_norm, Z_mu, 
                           cmap='viridis', 
                           edgecolor='none', 
                           alpha=0.8,
                           rstride=1, cstride=1)
    
    # è»¸ãƒ©ãƒ™ãƒ«ã®è¨­å®š
    ax.set_xlabel(f'Normalized Coupling K[{index1}]')
    ax.set_ylabel(f'Normalized Coupling K[{index2}]')
    ax.set_zlabel('Predicted Fitness ($\mu$ = F)')
    ax.set_title('ANN Surrogate Model Landscape (Smoothed)')
    
    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã®è¿½åŠ 
    fig.colorbar(surf, shrink=0.5, aspect=5, label='Predicted Fitness')
    
    plt.show()


# 10ä¸‡ç‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å¹³å‡ã‚’ç›´æ¥è¿”ã™é–¢æ•°
def acquisition_function_ann(K_candidate, ensemble_models):
    mu, _ = predict_ensemble(K_candidate.reshape(1, -1), ensemble_models)
    return mu # CMA-ESã¯ã“ã® mu ã‚’æœ€å°åŒ–ã™ã‚‹
    
#R^2è¨ˆç®—ç”¨bulk
def predict_ensemble_mu_bulk(X_data: np.ndarray, ensemble_models: List[MLPRegressor]) -> np.ndarray:
    """
    è¤‡æ•°ç‚¹ï¼ˆãƒãƒ«ã‚¯ï¼‰ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ X_data ã«å¯¾ã—ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å¹³å‡(Î¼)ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """
    # X_data ãŒãƒªã‚¹ãƒˆã§æ¥ã‚‹å¯èƒ½æ€§ã«å‚™ãˆã€ã“ã“ã§ndarrayã«å¤‰æ›ï¼ˆå¿µã®ãŸã‚ï¼‰
    if isinstance(X_data, list):
        X_data = np.array(X_data)
        
    predictions = np.array([model.predict(X_data).flatten() for model in ensemble_models])
    mu = np.mean(predictions, axis=0)
    return mu

FILENAME_PREFIX = "mrr_sao_model"
#FSR=20nm
def save_sao_state(ensemble_models, X_train, Y_train, best_K_norm, best_fitness):
    """ANNã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚"""
    try:
        joblib.dump(ensemble_models, f'{FILENAME_PREFIX}_20_2ensemble.pkl')
        np.save(f'{FILENAME_PREFIX}_20X_2_train.npy', np.array(X_train))
        np.save(f'{FILENAME_PREFIX}_20Y_2_train.npy', np.array(Y_train))
        metadata = {'best_K_norm': best_K_norm, 'best_fitness': best_fitness}
        joblib.dump(metadata, f'{FILENAME_PREFIX}_20_2metadata.pkl')
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ ({len(X_train)}ç‚¹) ã‚’æ­£å¸¸ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def load_sao_state():
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚"""
    try:
        ensemble_models = joblib.load(f'{FILENAME_PREFIX}_20_2ensemble.pkl')
        X_train = np.load(f'{FILENAME_PREFIX}_20X_2_train.npy').tolist()
        Y_train = np.load(f'{FILENAME_PREFIX}_20Y_2_train.npy').tolist()
        metadata = joblib.load(f'{FILENAME_PREFIX}_20_2metadata.pkl')
        print("âœ… è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        return ensemble_models, X_train, Y_train, metadata['best_K_norm'], metadata['best_fitness'], True
    except FileNotFoundError:
        print("ğŸš¨ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ã«SAOã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚")
        return None, [], [], None, float("inf"), False
#FSR=35
"""
def save_sao_state(ensemble_models, X_train, Y_train, best_K_norm, best_fitness):
    #ANNã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
    try:
        joblib.dump(ensemble_models, f'{FILENAME_PREFIX}_35ensemble.pkl')
        np.save(f'{FILENAME_PREFIX}_35X_train.npy', np.array(X_train))
        np.save(f'{FILENAME_PREFIX}_35Y_train.npy', np.array(Y_train))
        metadata = {'best_K_norm': best_K_norm, 'best_fitness': best_fitness}
        joblib.dump(metadata, f'{FILENAME_PREFIX}_35metadata.pkl')
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ ({len(X_train)}ç‚¹) ã‚’æ­£å¸¸ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def load_sao_state():
    #ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚
    try:
        ensemble_models = joblib.load(f'{FILENAME_PREFIX}_35ensemble.pkl')
        X_train = np.load(f'{FILENAME_PREFIX}_35X_train.npy').tolist()
        Y_train = np.load(f'{FILENAME_PREFIX}_35Y_train.npy').tolist()
        metadata = joblib.load(f'{FILENAME_PREFIX}_35metadata.pkl')
        print("âœ… è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        return ensemble_models, X_train, Y_train, metadata['best_K_norm'], metadata['best_fitness'], True
    except FileNotFoundError:
        print("ğŸš¨ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ã«SAOã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚")
        return None, [], [], None, float("inf"), False
"""
def optimize_K(
    eta: float,
    number_of_rings: int,
    rng: np.random.Generator,
    params: OptimizeKParams,
    build_model_only: bool = False,
) -> tuple[npt.NDArray[np.float_], float]:
    #-----åˆæœŸè¨­å®š-----
    N_dim = number_of_rings + 1
    ensemble_models, X_train, Y_train, best_K_norm, best_fitness, loaded = load_sao_state()
    bounds_normalized = np.array([(0.0, 1.0) for _ in range(N_dim)])

    if not loaded:
        hidden_layer_sizes = (512,256,128,128) 
        NUM_ENSEMBLE = 1
        base_ann_model = MLPRegressor(
            hidden_layer_sizes=hidden_layer_sizes, 
            max_iter=30000, 
            learning_rate_init = 0.0005,
            activation='relu', 
            solver='adam', 
            random_state=42,
            verbose = True,
            n_iter_no_change = 100
        )
        ensemble_models = [clone(base_ann_model) for _ in range(NUM_ENSEMBLE)]
    #å¤‰æ•°
        initial_samples = 50000 # å‡¹å‡¸å¯¾ç­–ã¨ã—ã¦10Nã«å¢—ã‚„ã™
    #ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        X_train = []
        Y_train = []
        best_K_norm: Optional[np.ndarray] = None
        best_fitness = float("inf")
        
    
    #-----ãƒ‡ãƒ¼ã‚¿åé›†-----
        print("ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
        lhs = LatinHypercube(d=N_dim, seed=rng)
        initial_K_samples = lhs.random(n = initial_samples)
        for K_sample in initial_K_samples:
        #è©•ä¾¡é–¢æ•°ã§è¨ˆç®—
            K_sample_phy = denormalize_K(K_sample,params.eta)
            train_fitness = optimize_K_func(K_sample_phy,params)
            X_train.append(K_sample)
            Y_train.append(train_fitness)

            if train_fitness < best_fitness:
                best_fitness = train_fitness
                best_K_norm = K_sample
        # ãƒ‡ãƒ¼ã‚¿åé›†ãƒ«ãƒ¼ãƒ—ã®ç›´å¾Œã«è¿½åŠ 
            Y_arr_initial = np.array(Y_train)

        print(f"æœ€å¤§å€¤ (æœ€è‰¯ã®è§£): {Y_arr_initial.min():.6f}")
    X_full_arr = np.array(X_train)
    Y_full_arr = np.array(Y_train).ravel() # Y_trainã¯å¹³å¦åŒ–

    # å…¨ãƒ‡ãƒ¼ã‚¿ (X_train, Y_train) ã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²
    # X_train_split: è¨“ç·´ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ (90%)
    # X_test: è¨ºæ–­ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ (10%)
    X_train_split, X_test, Y_train_split, Y_test = train_test_split(
        X_full_arr, 
        Y_full_arr, 
        test_size=0.1, 
        random_state=42 # å†ç¾æ€§ã®ç¢ºä¿
    )
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†å‰²ã—ã¾ã—ãŸ: è¨“ç·´ç‚¹æ•°={len(X_train_split)}, ãƒ†ã‚¹ãƒˆç‚¹æ•°={len(X_test)}")
    
    
    # ğŸš¨ ã€ä¿®æ­£ 2ã€‘: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã«åˆ†å‰²å¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    # X_arr = np.array(X_train)  <-- å…ƒã€…ã“ã®è¡ŒãŒã‚ã£ãŸå ´åˆã€å‰Šé™¤/ç½®æ›
    # Y_arr = np.array(Y_train)  <-- å…ƒã€…ã“ã®è¡ŒãŒã‚ã£ãŸå ´åˆã€å‰Šé™¤/ç½®æ›
    X_arr = X_train_split # åˆ†å‰²å¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿
    Y_arr = Y_train_split # åˆ†å‰²å¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿
    #for iteration in range (MAX_SAO_ITERATIONS):
        #current_beta = get_beta_schedule(iteration, MAX_SAO_ITERATIONS)
        #X_arr_1 = np.array(X_train)
        #Y_arr_1 = np.array(Y_train)
    for model in ensemble_models:
            model.fit(X_arr,Y_arr.ravel())
    save_sao_state(ensemble_models, X_train, Y_train, best_K_norm, best_fitness)
    print(f"STEP 3: SAOãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†ã€‚")
    if build_model_only:
            # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ã¿ã‚’ç›®çš„ã¨ã™ã‚‹å ´åˆã€ã“ã“ã§çµ‚äº†
        return denormalize_K(best_K_norm, eta), -best_fitness
    
    
    Y_train_pred = predict_ensemble_mu_bulk(X_train_split, ensemble_models)
    Y_test_pred = predict_ensemble_mu_bulk(X_test, ensemble_models)

    r2_train = r2_score(Y_train_split, Y_train_pred)
    r2_test = r2_score(Y_test, Y_test_pred)
    
    # check_overfittingã®è¨ºæ–­ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç›´æ¥ã“ã“ã«çµ„ã¿è¾¼ã‚€
    print("--- R^2 ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹éå­¦ç¿’è¨ºæ–­ ---")
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ R^2: {r2_train:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ R^2: {r2_test:.4f}")
    
    if r2_train > 0.99 and r2_test < 0.90:
        print("\nğŸš¨ è¨ºæ–­çµæœ: é‡å¤§ãªéå­¦ç¿’ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚")
        print("â–¶ï¸ è§£æ±ºç­–: 'alpha' (æ­£å‰‡åŒ–) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã—ã¦å†è¨“ç·´ã—ã¦ãã ã•ã„ã€‚")
    elif r2_train < 0.90:
        print("\nâš ï¸ è¨ºæ–­çµæœ: ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆå­¦ç¿’ä¸è¶³ï¼‰ã§ã™ã€‚")
    else:
        print("\nâœ… è¨ºæ–­çµæœ: æ±åŒ–æ€§èƒ½ã¯è‰¯å¥½ã§ã™ã€‚æœ€é©åŒ–ã®å•é¡Œã¯æ¢ç´¢æˆ¦ç•¥ã«ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚") 
    #-----ç²å¾—é–¢æ•°ã®æœ€é©åŒ–-----
    if not build_model_only:
        
        def final_optimization_wrapper(K_candidate):
            return acquisition_function_ann(K_candidate, ensemble_models)
        
    # æœ€é©åŒ–ã®åˆæœŸã‚¹ã‚¿ãƒ¼ãƒˆç‚¹: åˆæœŸãƒ‡ãƒ¼ã‚¿ã§è¦‹ã¤ã‘ãŸæœ€è‰¯ç‚¹ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ
        initial_start_norm = best_K_norm if best_K_norm is not None else np.full(N_dim, 0.5)
    
    # CMA-ESã®æœ€çµ‚å®Ÿè¡Œ (ç²å¾—é–¢æ•°ãªã—ã€ç›´æ¥Î¼ã‚’æœ€å°åŒ–)
        final_K_norm, final_fitness = cma_run(
            initial=initial_start_norm, 
            bounds_array=bounds_normalized,
            popsize=4 + math.floor(3 * math.log(number_of_rings+1)) + 8,
            sigma=0.3, # ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã¯0.3~0.5ç¨‹åº¦ã®å®‰å®šã—ãŸå€¤ã§è‰¯ã„
            generations=500, # åæŸã™ã‚‹ã¾ã§ååˆ†ãªä¸–ä»£æ•°ã‚’ç¢ºä¿
            params=params,
            objective_func=final_optimization_wrapper 
        )
    
    #-----ã€æœ€çµ‚æ¤œè¨¼ã€‘-----
    # CMA-ESãŒè¦‹ã¤ã‘ãŸæœ€é©è§£ã‚’ã€æœ€å¾Œã«ä¸€åº¦ã ã‘çœŸã®è©•ä¾¡é–¢æ•°ã§æ¤œè¨¼ã™ã‚‹
        final_K_phy = denormalize_K(final_K_norm, params.eta)
        true_final_fitness = optimize_K_func(final_K_phy, params)
    
        print(f"æœ€çµ‚æ¤œè¨¼: CMA-ESäºˆæ¸¬={final_fitness:.6f}, çœŸã®è©•ä¾¡å€¤={true_final_fitness:.6f}")
    
    # --- å¯è¦–åŒ–ã¯æ®‹ã™ãŒã€å…ƒã®ã‚³ãƒ¼ãƒ‰ã«ã¯å«ã¾ã‚Œã¦ã„ãªã„ãŸã‚é–¢æ•°å‘¼ã³å‡ºã—ã®ã¿æ®‹ã™ ---
        visualize_ann_landscape(ensemble_models, params, number_of_rings)
        #r2_train, r2_test = check_overfitting(ensemble_models, X_train, Y_train, X_test, Y_test)
        
    
    # ----- [æœ€çµ‚çµæœ] -----
        E: float = -true_final_fitness
        K: npt.NDArray[np.float_] = final_K_phy # éæ­£è¦åŒ–ã•ã‚ŒãŸKã‚’è¿”ã™

        return K, E
    """
        def acquisition_wrapper(K_candidate):
            return acquisition_function_ann(K_candidate, ensemble_models)
        lower_bounds = bounds_normalized[:, 0]
        upper_bounds = bounds_normalized[:, 1]

        if best_K_norm is None or rng.uniform(0, 1) < 0.9: 
    # ãƒ‡ãƒ¼ã‚¿åé›†ãŒã¾ã æˆåŠŸã—ã¦ã„ãªã„å ´åˆã€ã¾ãŸã¯æ¢ç´¢ã‚’å¼·åˆ¶ã™ã‚‹å ´åˆ
            lower_bounds = bounds_normalized[:, 0]
            upper_bounds = bounds_normalized[:, 1]
            initial_start_norm = rng.uniform(low=lower_bounds, high=upper_bounds, size=(N_dim,))
        else:
    # æœ€è‰¯è§£ã®è¿‘å‚ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ (æ´»ç”¨)
            initial_start_norm = best_K_norm
        acq_best_K, _ = cma_run(
            initial=initial_start_norm, 
            bounds_array=bounds_normalized,
            popsize=4 + math.floor(3 * math.log(number_of_rings+1)) + 8, 
            sigma=1.0, 
            generations=200, 
            params=params,
            objective_func=acquisition_wrapper 
        )
        
    #-----çœŸå€¤ã®å†è©•ä¾¡ã¨ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°-----
        # ç²å¾—é–¢æ•°ãŒææ¡ˆã—ãŸç‚¹ (acq_best_K) ã‚’å…ƒã®è©•ä¾¡é–¢æ•°ã§ç¢ºèª
        print(acq_best_K)
        acq_best_K_phy = denormalize_K(acq_best_K,params.eta)
        true_fitness_new = optimize_K_func(acq_best_K_phy, params)
        
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ›´æ–°
        X_train.append(acq_best_K)
        Y_train.append(true_fitness_new)
        print(f"ä»Šå›ã®è©•ä¾¡å€¤",true_fitness_new)
        #print(best_fitness)
        # å…¨ä½“ã®æœ€è‰¯è§£ã‚’æ›´æ–°
        if true_fitness_new < best_fitness:
            best_fitness = true_fitness_new
            best_K_norm = acq_best_K
            
        print(f"STEP 4: çœŸå€¤å†è©•ä¾¡å®Œäº†ã€‚Best Fitness (True) = {best_fitness:.6f}")

    print(">>> 3D SAOãƒ¢ãƒ‡ãƒ«ã®åœ°å½¢ã‚’å¯è¦–åŒ–ä¸­...")
            # è¨“ç·´æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¯è¦–åŒ–é–¢æ•°ã«æ¸¡ã™
    visualize_ann_landscape(ensemble_models, params, number_of_rings)
    # ----- [æœ€çµ‚çµæœ] -----
    E: float = -best_fitness
    K: npt.NDArray[np.float_] = denormalize_K(best_K_norm if best_K_norm is not None else np.zeros(N_dim), params.eta)

    return K, E
    """
def optimize(
    n_g: float,
    n_eff: float,
    eta: float,
    alpha: float,
    center_wavelength: float,
    length_of_3db_band: float,
    FSR: float,
    max_crosstalk: float,
    H_p: float,
    H_s: float,
    H_i: float,
    r_max: float,
    weight: list[float],
    min_ring_length: float,
    number_of_rings: int,
    number_of_generations: int,
    strategy: list[float],
    logger: Logger,
    skip_plot: bool = False,
    seedsequence: np.random.SeedSequence = np.random.SeedSequence(),
) -> None:
    rng = get_differential_evolution_rng(seedsequence=seedsequence)
    N_list: list[npt.NDArray[np.int_]] = [np.array([]) for _ in range(number_of_generations)]
    L_list: list[npt.NDArray[np.float_]] = [np.array([]) for _ in range(number_of_generations)]
    K_list: list[npt.NDArray[np.float_]] = [np.array([]) for _ in range(number_of_generations)]
    FSR_list: npt.NDArray[np.float_] = np.zeros(number_of_generations, dtype=np.float_)
    E_list: list[float] = [0 for _ in range(number_of_generations)]
    method_list: list[int] = [0 for _ in range(number_of_generations)]
    best_E_list: list[float] = [0 for _ in range(number_of_generations)]
    analyze_score_list: list[float] = [0 for _ in range(number_of_generations)]
    for m in range(number_of_generations):
        N: npt.NDArray[np.int_]
        L: npt.NDArray[np.float_]
        practical_FSR: np.float_

        kind: npt.NDArray[np.int_]
        counts: npt.NDArray[np.int_]

        if m < 10:
            method: int = 4
        else:
            method = rng.choice([1, 2, 3, 4], p=strategy)

        if method == 1:
            max_index = np.argmax(E_list)
            max_N = N_list[max_index]

            kind, counts = rng.permutation(np.unique(max_N, return_counts=True), axis=1)  # type: ignore
            N = np.repeat(kind, counts)
            L = calculate_ring_length(center_wavelength=center_wavelength, n_eff=n_eff, N=N)
            practical_FSR = calculate_practical_FSR(center_wavelength=center_wavelength, n_eff=n_eff, n_g=n_g, N=N)
        elif method == 2:
            max_index = np.argmax(E_list)
            max_N = N_list[max_index]
            N = rng.permutation(max_N)
            L = calculate_ring_length(center_wavelength=center_wavelength, n_eff=n_eff, N=N)
            practical_FSR = calculate_practical_FSR(center_wavelength=center_wavelength, n_eff=n_eff, n_g=n_g, N=N)
        elif method == 3:
            max_index = np.argmax(E_list)
            max_N = N_list[max_index]
            kind = np.unique(max_N)  # type: ignore
            N = rng.choice(kind, number_of_rings)
            while not set(kind) == set(N):
                N = rng.choice(kind, number_of_rings)
            L = calculate_ring_length(center_wavelength=center_wavelength, n_eff=n_eff, N=N)
            practical_FSR = calculate_practical_FSR(center_wavelength=center_wavelength, n_eff=n_eff, n_g=n_g, N=N)
        else:
            N, L, practical_FSR = optimize_L(
                n_g=n_g,
                n_eff=n_eff,
                FSR=FSR,
                center_wavelength=center_wavelength,
                min_ring_length=min_ring_length,
                number_of_rings=number_of_rings,
                rng=rng,
            )
        N = [78,78,78,117,117,117] #6th
       # N = [88,88,110,110,110,110]
        #N = [110,110,88,88,88,88,110,110]
        #N = [78,78,78,468,468,117,117,117] #8th
        #N = [117,117,117,156,156,156,117,117,156,156] #10th
        #N = [117,117,117,117,468,468,468,78,78,78,78,78] #12th
        #N = [117,117,117,117,468,468,468,468,78,78,78,78,78,78] #14th
        
        L = calculate_ring_length(center_wavelength=center_wavelength, n_eff=n_eff, N=N)
        normal_evaluations = []
        perturbed_evaluations = []
       
        K, E = optimize_K(
            eta=eta,
            number_of_rings=number_of_rings,
            rng=rng,
            params=OptimizeKParams(
                L=L,
                n_g=n_g,
                n_eff=n_eff,
                eta=eta,
                alpha=alpha,
                center_wavelength=center_wavelength,
                length_of_3db_band=length_of_3db_band,
                FSR=practical_FSR,
                max_crosstalk=max_crosstalk,
                H_p=H_p,
                H_s=H_s,
                H_i=H_i,
                r_max=r_max,
                weight=weight,
            ),
        )
        N_list[m] = N
        L_list[m] = L
        FSR_list[m] = practical_FSR
        K_list[m] = K
        E_list[m] = E
        analyze_score = 0.0
        """
        if E > 20:
            for L_error_rate, K_error_rate in zip([0.01, 0.1, 1, 10], [1, 10, 100]):
                analyze_result = analyze(
                    n=1000,
                    L_error_rate=L_error_rate,
                    K_error_rate=K_error_rate,
                    L=L,
                    K=K,
                    n_g=n_g,
                    n_eff=n_eff,
                    eta=eta,
                    alpha=alpha,
                    center_wavelength=center_wavelength,
                    length_of_3db_band=length_of_3db_band,
                    FSR=FSR,
                    max_crosstalk=max_crosstalk,
                    H_p=H_p,
                    H_s=H_s,
                    H_i=H_i,
                    r_max=r_max,
                    weight=weight,
                    min_ring_length=min_ring_length,
                    seedsequence=seedsequence,
                    skip_plot=True,
                    logger=logger,
                )
                if analyze_result > 0.5:
                    analyze_score += 1
            analyze_score_list[m] = analyze_score
        """
        best_index = np.argmax(E_list)
        best_N = N_list[best_index]
        best_L = L_list[best_index]
        best_K = K_list[best_index]
        best_FSR = FSR_list[best_index]
        best_E = E_list[best_index]
        best_analyze_score = analyze_score_list[best_index]
        print(m + 1)
        logger.print_parameters(K=K, L=L, N=N, FSR=practical_FSR, E=E, analyze_score=analyze_score, format=True)
        print("==best==")
        logger.print_parameters(
            K=best_K, L=best_L, N=best_N, FSR=best_FSR, E=best_E, analyze_score=best_analyze_score, format=True
        )
        
        print("================")
        
        method_list[m] = method
        best_E_list[m] = best_E

    max_index = np.argmax(E_list)
    result_N = N_list[max_index]
    result_L = L_list[max_index]
    result_K = K_list[max_index]
    result_FSR = FSR_list[max_index]
    result_E = E_list[max_index]
    result_analyze_score = analyze_score_list[max_index]
    x = calculate_x(center_wavelength=center_wavelength, FSR=result_FSR)
    y = simulate_transfer_function(
        wavelength=x,
        L=result_L,
        K=result_K,
        alpha=alpha,
        eta=eta,
        n_eff=n_eff,
        n_g=n_g,
        center_wavelength=center_wavelength,
    )
    print("result")
    
    logger.print_parameters(
        K=result_K, L=result_L, N=result_N, FSR=result_FSR, E=result_E, analyze_score=result_analyze_score
    )

    logger.save_result(L=result_L, K=result_K)
    print("save data")
    logger.save_DE_data(
        N_list=N_list,
        L_list=L_list,
        K_list=K_list,
        FSR_list=FSR_list,
        E_list=E_list,
        method_list=method_list,
        best_E_list=best_E_list,
        analyze_score_list=analyze_score_list,
    )
    print("end")
    if E > 0 and not skip_plot:
        graph = Graph()
        graph.create()
        graph.plot(x, y)
        graph.show(logger.generate_image_path())
        plt.figure()
        plt.plot(x, y)
        plt.title("Transfer Function")
        plt.xlabel("Wavelength (nm)")
        plt.ylabel("Transmittance (dB)")
        plt.grid(True)
        plt.show()


def optimize_K_func(K: npt.NDArray[np.float_], params: OptimizeKParams) -> np.float_:
    # K_minã¨K_maxã‚’å®šç¾©

    K_min = 1e-12
    K_max = params.eta
    
    # --- ã€ä»£æ›¿ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°å‡¦ç†ã®å†é©ç”¨ã€‘ ---
    # KãŒæµ®å‹•å°æ•°ç‚¹èª¤å·®ã§ã‚ãšã‹ã« eta_max ã‚’è¶…ãˆã‚‹ã®ã‚’é˜²ã
    K_clamped = np.minimum(K, K_max)
    K_clamped = np.maximum(K_clamped, K_min)
    # ----------------------------------------

    

    x = calculate_x(center_wavelength=params.center_wavelength, FSR=params.FSR)
    y = simulate_transfer_function(
        wavelength=x,
        L=params.L,
        K=K_clamped,
        alpha=params.alpha,
        eta=params.eta,
        n_eff=params.n_eff,
        n_g=params.n_g,
        center_wavelength=params.center_wavelength,
    )
    #print(f"x: {x}")
    #print(f"y: {y}")
    

    

    return -evaluate_band(
        x=x,
        y=y,
        center_wavelength=params.center_wavelength,
        length_of_3db_band=params.length_of_3db_band,
        max_crosstalk=params.max_crosstalk,
        H_p=params.H_p,
        H_s=params.H_s,
        H_i=params.H_i,
        r_max=params.r_max,
        weight=params.weight,
        ignore_binary_evaluation=False,
    )
    #print(f"Fitness value: {fitness}")
"""
def optimize_perturbed_K_func(K: npt.NDArray[np.float_], params: OptimizeKParams) -> tuple[float, float]:

    
    #èª¤å·®ã¨ã—ã¦çµåˆç‡ K ã« +0.005 ãŠã‚ˆã³ -0.005 ã‚’é©ç”¨ã—ãŸå ´åˆã®è©•ä¾¡å€¤ã‚’è¨ˆç®—ã€‚

    #Parameters:
    #- K: çµåˆç‡ã®é…åˆ—
    #- params: æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    #Returns:
   # - E_positive: +0.005 ã®èª¤å·®ã‚’åŠ ãˆãŸå ´åˆã®è©•ä¾¡å€¤
    #- E_negative: -0.005 ã®èª¤å·®ã‚’åŠ ãˆãŸå ´åˆã®è©•ä¾¡å€¤
    

    # æ­£ã®èª¤å·®ã‚’åŠ ãˆã‚‹
    perturbed_K_positive = np.clip(K + 0.005, 1e-12, params.eta)

    # è² ã®èª¤å·®ã‚’åŠ ãˆã‚‹
    perturbed_K_negative = np.clip(K - 0.005, 1e-12, params.eta)

    # æ³¢é•·ã‚’è¨ˆç®—
    x = calculate_x(center_wavelength=params.center_wavelength, FSR=params.FSR)

    # æ­£ã®èª¤å·®ã§ã®è©•ä¾¡å€¤
    y_positive = simulate_transfer_function(
        wavelength=x,
        L=params.L,
        K=perturbed_K_positive,
        alpha=params.alpha,
        eta=params.eta,
        n_eff=params.n_eff,
        n_g=params.n_g,
        center_wavelength=params.center_wavelength,
    )
    E_positive = -evaluate_band(
        x=x,
        y=y_positive,
        center_wavelength=params.center_wavelength,
        length_of_3db_band=params.length_of_3db_band,
        max_crosstalk=params.max_crosstalk,
        H_p=params.H_p,
        H_s=params.H_s,
        H_i=params.H_i,
        r_max=params.r_max,
        weight=params.weight,
        ignore_binary_evaluation=False,
    )

    # è² ã®èª¤å·®ã§ã®è©•ä¾¡å€¤
    y_negative = simulate_transfer_function(
        wavelength=x,
        L=params.L,
        K=perturbed_K_negative,
        alpha=params.alpha,
        eta=params.eta,
        n_eff=params.n_eff,
        n_g=params.n_g,
        center_wavelength=params.center_wavelength,
    )
    E_negative = -evaluate_band(
        x=x,
        y=y_negative,
        center_wavelength=params.center_wavelength,
        length_of_3db_band=params.length_of_3db_band,
        max_crosstalk=params.max_crosstalk,
        H_p=params.H_p,
        H_s=params.H_s,
        H_i=params.H_i,
        r_max=params.r_max,
        weight=params.weight,
        ignore_binary_evaluation=False,
    )
 

    return E_positive, E_negative
    """

